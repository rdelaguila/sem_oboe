{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7068b5-a242-486d-88eb-ca25acf8e2b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringCaseInsensitiveSet, CaseInsensitiveDict, CaseInsensitiveSet\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriplet_manager_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tripleta\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moperator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m itemgetter\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import spacy\n",
    "import torch\n",
    "from utils.types import StringCaseInsensitiveSet, CaseInsensitiveDict, CaseInsensitiveSet\n",
    "from utils.triplet_manager_lib import Tripleta\n",
    "from operator import itemgetter\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, T5Tokenizer, T5ForConditionalGeneration\n",
    "import joblib\n",
    "\n",
    "# ======== OWN CONFIG ========\n",
    "TRIPLES_PATH      = \"data/triples_ft/processed/dataset_final_triplet_bbc_pykeen\"\n",
    "# CSV con columnas [subject, relation, object, topic]\n",
    "TOPIC_ID          = 3                       # ID del tópico a procesar\n",
    "VISITAR_OBJETO    = True                     # incluir objetos en el filtrado\n",
    "TERMINOS_A_INCLUIR  = set(['dvd','google','electronic','tv','sony','screen','nintendo','player','mobile','phone','software','video','network','apple','program','linux'])                    # set de términos relevantes (None para todos)\n",
    "DBPEDIA_PATH = 'data/corpus_ft/bbc/diccionario_topic_entidades_dbpedia'\n",
    "DICTNER_PATH      = 'data/corpus_ft/bbc/diccionario_ner'     # JSON precomputado de entidades NER\n",
    "N_SINONIMOS       = 1                        # número de tipos más similares a retener\n",
    "OUTPUT_DIR        = 'output'\n",
    "SPACY_MODEL       = 'en_core_web_lg'        # modelo spaCy para similitud\n",
    "# Qwen 2.5 generación\n",
    "gen_model_name    = 'Qwen/Qwen2-7B-Instruct'\n",
    "# mT5 evaluación\n",
    "eval_model_name   = 'google/mt5-small'\n",
    "nlp = spacy.load(SPACY_MODEL)\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c2a186-4621-4e1b-89a2-5c028c15c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================ REVISAR\n",
    "topics_entsdbpedia = joblib.load(DBPEDIA_PATH)\n",
    "diccionario_dbpedia = topics_entsdbpedia.get(TOPIC_ID, {})\n",
    "\n",
    "dictdbp = diccionario_dbpedia\n",
    "dictner = joblib.load(DICTNER_PATH)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "# Carga recursos\n",
    "df_tr = joblib.load(TRIPLES_PATH)\n",
    "print (df_tr.shape)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "def remove_numbers(text): return re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "def remove_dbpedia_categories(s): return s.split('/')[-1]\n",
    "\n",
    "def return_url_element(s):\n",
    "    for sep in ['#','/']:\n",
    "        if sep in s:\n",
    "            s = s.split(sep)[-1]\n",
    "    return s\n",
    "\n",
    "# 1. Filtrado y extracción de tripletas relevantes\n",
    "listado_tripletas = []\n",
    "palabrasdbpedia = set(k.lower() for k in dictdbp.keys()) ## aqui\n",
    "print(\"dictdbp:\", dictdbp)\n",
    "print(\"len(dictdbp):\", len(dictdbp))\n",
    "print(\"Claves ejemplo:\", list(dictdbp.keys())[:10])\n",
    "anterior = None\n",
    "for i, row in df_tr.iterrows():\n",
    "    tripleta = Tripleta({'subject': str(row['subject']),\n",
    "                     'relation': row['relation'],\n",
    "                     'object': str(row['object'])})\n",
    "\n",
    "    sujeto = set(tripleta.sujeto.split())\n",
    "    objeto = set(tripleta.objeto.split()) if VISITAR_OBJETO else set()\n",
    "\n",
    "    # Si es la primera iteración\n",
    "    if anterior is None:\n",
    "        anterior = tripleta\n",
    "\n",
    "    # Comparación entre tripletas\n",
    "    misma_super = (tripleta.esTripletaSuper(anterior) == anterior.esTripletaSuper(tripleta))\n",
    "    dif = tripleta.dondeSonDiferentes(anterior)\n",
    "\n",
    "    if (misma_super and (dif == ('sujeto', 'relacion', 'objeto') or dif == ('sujeto', None, 'objeto'))):\n",
    "        anterior = tripleta\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Filtro por términos a incluir\n",
    "    if (TERMINOS_A_INCLUIR is None\n",
    "            or not TERMINOS_A_INCLUIR.isdisjoint(sujeto)\n",
    "            or (VISITAR_OBJETO and not TERMINOS_A_INCLUIR.isdisjoint(objeto))):\n",
    "\n",
    "        visitados = set()\n",
    "\n",
    "        # Crea set de términos existentes en dictdbp (en minúsculas)\n",
    "\n",
    "        encontradas = sujeto.intersection(palabrasdbpedia)\n",
    "        no_encontradas = sujeto.difference(palabrasdbpedia)\n",
    "\n",
    "        if VISITAR_OBJETO:\n",
    "            encontradas.update(objeto.intersection(palabrasdbpedia))\n",
    "            no_encontradas.update(objeto.difference(palabrasdbpedia))\n",
    "\n",
    "        final = encontradas.union(no_encontradas)\n",
    "\n",
    "        for termino in encontradas:\n",
    "            termino_lower = termino.lower()\n",
    "\n",
    "            if termino in visitados:\n",
    "                continue\n",
    "\n",
    "            if termino[0].isdigit():\n",
    "                no_encontradas.add(termino)\n",
    "                continue\n",
    "\n",
    "            info_list = dictdbp.get(termino_lower, [])\n",
    "            if not info_list:\n",
    "                no_encontradas.add(termino)\n",
    "                continue\n",
    "\n",
    "            info_termino = info_list[0]\n",
    "            uri_db = info_termino.get('URI', '')\n",
    "            tipos_db = info_termino.get('tipos', [])\n",
    "\n",
    "            sinonimos = []\n",
    "            lwordnet = []\n",
    "\n",
    "            # WordNet synonyms + hypernyms\n",
    "            for syn in wn.synsets(termino):\n",
    "                sinonimos.extend(syn.lemma_names())\n",
    "                for h in syn.hypernyms():\n",
    "                    lwordnet.extend(h.lemma_names())\n",
    "\n",
    "            # NER\n",
    "            sujeto_en_ner = dictner.get(termino_lower, '')\n",
    "            ner = []\n",
    "            if sujeto_en_ner:\n",
    "                ner.append(sujeto_en_ner)\n",
    "\n",
    "            diccionario_termino = {\n",
    "                'termino': termino,\n",
    "                'sinonimos': list(set(sinonimos)),\n",
    "                'resource': uri_db,\n",
    "                'dbpedia': tipos_db,\n",
    "                'ner': ner,\n",
    "                'wordnet': lwordnet\n",
    "            }\n",
    "\n",
    "            listado_tripletas.append(diccionario_termino)\n",
    "            visitados.add(termino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b19dc7-122a-43ff-88ea-51feb1ee2437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
